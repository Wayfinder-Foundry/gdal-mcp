# v1.1.0 Vector Parity & Composition - Testing Guide

**Branch:** `feat/vector-parity-v1.1`  
**Target Release:** Q1 2025  
**Focus:** Vector tool parity, cross-domain reflection, and natural composition

---

## Critical Research Questions

### Q1: Cross-Domain Reflection Cache Sharing
**Hypothesis:** CRS justification cache should work across raster and vector tools

**Test Scenario:**
```
1. User: "Reproject elevation.tif to EPSG:3857 with bilinear"
   → AI prompted for CRS justification
   → AI provides reasoning (Web Mercator for web mapping)
   → Cache stored: .preflight/justifications/crs_datum/sha256:xyz123.json

2. User: "Reproject boundaries.gpkg to EPSG:3857"
   → Middleware checks cache for dst_crs="EPSG:3857"
   → EXPECTED: Cache hit from step 1
   → EXPECTED: No re-prompting for CRS
   → AI proceeds immediately with cached reasoning

3. Verification:
   Check cache directory:
   $ ls .preflight/justifications/crs_datum/
   → Should see single SHA256 file used by both operations
```

**Success Criteria:**
- [ ] Cache hit occurs for vector operation after raster operation
- [ ] No redundant CRS prompting
- [ ] AI references previous justification naturally
- [ ] Cache file shared between both tools

**If Fails:**
- Debug cache key computation in middleware
- Verify domain consistency (`crs_datum` for both)
- Check args_fn extraction (dst_crs only)
- Examine middleware logs

---

### Q2: Natural Multi-Step Workflow Discovery
**Hypothesis:** AI can chain vector operations without explicit workflow prompts

**Test Scenario 1: Web Mapping Preparation**
```
User: "Prepare boundaries.shp for web mapping"

Expected AI workflow:
1. vector_reproject(dst_crs="EPSG:3857")
2. vector_simplify(tolerance=100, preserve_topology=true)
3. vector_convert(output="boundaries.geojson")

Measure:
- Does AI discover this chain autonomously?
- Does it ask for clarification on tolerance/simplification?
- Does it explain each step?
```

**Test Scenario 2: Format Migration**
```
User: "Migrate this old shapefile to a modern format"

Expected AI workflow:
1. vector_convert(output="data.gpkg", driver="GPKG")
2. Optional: vector_reproject if CRS standardization mentioned

Measure:
- Does AI choose GeoPackage as "modern"?
- Does it explain benefits (single file, UTF-8, no size limits)?
```

**Test Scenario 3: Spatial Subset**
```
User: "Extract features within this bounding box and prepare for analysis"

Expected AI workflow:
1. vector_clip(bounds=[...])
2. vector_reproject(dst_crs=<analysis CRS>)
3. vector_convert(output=<working format>)

Measure:
- Does AI ask for target CRS?
- Does it handle bbox input naturally?
```

**Success Criteria:**
- [ ] AI chains 2-3 operations for common tasks
- [ ] Explanations are contextual and educational
- [ ] No artificial workflow prompts needed
- [ ] Operations execute in logical order

---

### Q3: Reflection Reuse Across Operations
**Hypothesis:** Same CRS justification reused across multiple vector operations

**Test Scenario:**
```
1. User: "Reproject boundaries.gpkg to UTM Zone 10N"
   → CRS justified with rationale
   
2. User: "Also reproject roads.geojson to UTM Zone 10N"
   → EXPECTED: Cache hit, no re-prompting
   
3. User: "And the buildings.shp to UTM Zone 10N"
   → EXPECTED: Cache hit again
   
Measure:
- Cache hit rate: Should be 100% for same CRS
- AI mentions "using UTM Zone 10N (previously justified)"
- Workflow efficiency: fast execution after first justification
```

---

## Tool-Specific Tests

### vector_reproject

**Test 1: Basic Reprojection**
```bash
# Setup
Create test.geojson with simple polygon in EPSG:4326

# Test
User: "Reproject test.geojson to EPSG:3857"

Expected:
- CRS justification prompt (first use)
- Output: test_3857.gpkg (or .geojson if specified)
- Feature count preserved
- Bounds in EPSG:3857
- Geometry type preserved
```

**Test 2: Source CRS Override**
```bash
# Setup
Create shapefile without .prj file

# Test
User: "Reproject missing_crs.shp to EPSG:32610, assume source is EPSG:4326"

Expected:
- Accepts src_crs parameter
- Proceeds with override
- Warning/info about CRS assumption
```

**Test 3: Multiple Formats**
```bash
Input formats to test:
- [ ] Shapefile → GeoPackage
- [ ] GeoJSON → Shapefile
- [ ] GeoPackage → GeoJSON
- [ ] KML → GeoPackage

All should:
- Preserve attributes
- Transform geometries correctly
- Auto-detect output format from extension
```

---

### vector_convert

**Test 1: Shapefile to GeoPackage**
```bash
# Common migration scenario
Input: legacy.shp with encoding issues
Output: modern.gpkg

Expected:
- UTF-8 encoding in output
- Single file (no .shx, .dbf, .prj clutter)
- All attributes preserved
- Geometry intact
```

**Test 2: GeoJSON to Shapefile**
```bash
# Web to desktop workflow
Input: web_data.geojson
Output: desktop.shp

Expected:
- Field name truncation warnings (10 char limit)
- Encoding specification (UTF-8 vs ISO-8859-1)
- Multiple files created (.shp, .shx, .dbf, .prj)
```

**Test 3: Format Auto-Detection**
```bash
# AI should infer driver from extension
User: "Convert data.gpkg to data.geojson"

Expected:
- No explicit driver parameter needed
- GeoJSON driver selected automatically
- Pretty-printed JSON output
```

---

### vector_clip

**Test 1: Bounding Box Clip**
```bash
Input: large_dataset.gpkg
Bounds: [-123.0, 49.0, -122.0, 50.0]  # Vancouver area

Expected:
- Features outside bbox removed
- Features intersecting bbox clipped
- Partial geometries handled correctly
- Feature count < input count
```

**Test 2: Geometry Mask Clip**
```bash
Input: province_data.gpkg
Mask: city_boundary.geojson

Expected:
- Only features within city retained
- Clip respects mask geometry precisely
- Attributes preserved for retained features
```

---

### vector_buffer

**Test 1: Metric Buffer**
```bash
Input: points.geojson (EPSG:32610 - UTM Zone 10N)
Distance: 1000 (meters)

Expected:
- Circular buffers around points
- 1000m radius in projected units
- Polygons as output geometry type
```

**Test 2: Geographic Buffer**
```bash
Input: locations.geojson (EPSG:4326 - lat/lon)
Distance: 0.1 (degrees)

Expected:
- Warning about degree-based buffering?
- Buffer in degrees (approximation)
- Better: AI suggests reprojecting to metric CRS first?
```

---

### vector_simplify

**Test 1: Douglas-Peucker**
```bash
Input: detailed_coastline.gpkg (10000 vertices)
Tolerance: 100 (meters)
Method: douglas-peucker

Expected:
- Reduced vertex count (e.g., 2000 vertices)
- General shape preserved
- Smaller file size
- preserve_topology=true by default
```

**Test 2: Tolerance Impact**
```bash
Same input, different tolerances:
- 10m: minimal simplification, high detail
- 100m: moderate simplification, good for web
- 1000m: aggressive simplification, generalized

Expected:
- AI explains tradeoffs
- Suggests tolerance based on use case
- Shows before/after vertex counts
```

---

## Composition Testing

### Pattern 1: Web Mapping Workflow
```
Task: "Prepare this shapefile for web display"

Ideal sequence:
1. vector_reproject(EPSG:3857)
2. vector_simplify(tolerance=50-100)
3. vector_convert(GeoJSON or vector tiles)

Measure:
- Does AI discover this naturally?
- Are steps explained educationally?
- Does reflection work smoothly?
```

### Pattern 2: Analysis Preparation
```
Task: "Set up these datasets for spatial analysis in QGIS"

Ideal sequence:
1. vector_reproject(common CRS, e.g., UTM)
2. vector_clip(study area)
3. vector_convert(GeoPackage for single-file portability)

Measure:
- Does AI ask about target CRS?
- Does it handle multiple inputs?
- Are outputs organized logically?
```

### Pattern 3: Data Cleaning
```
Task: "Clean up this old shapefile and optimize it"

Ideal sequence:
1. vector_convert(GPKG for UTF-8 encoding)
2. vector_simplify(remove excess vertices)
3. Optional: vector_clip(remove outliers)

Measure:
- Does AI identify issues (encoding, complexity)?
- Are improvements explained?
- Is output demonstrably better?
```

---

## Session Tracking Tests

**Test: Multi-Operation Tracking**
```
Session workflow:
1. vector_reproject(EPSG:3857) 
2. vector_simplify(tolerance=100)
3. vector_convert(GeoJSON)

Expected session log (.preflight/sessions/{id}.json):
{
  "session_id": "...",
  "operations": [
    {"tool": "vector_reproject", "timestamp": "...", "params": {...}},
    {"tool": "vector_simplify", "timestamp": "...", "params": {...}},
    {"tool": "vector_convert", "timestamp": "...", "params": {...}}
  ],
  "justifications_referenced": ["crs_datum/sha256:abc123"]
}

Measure:
- Is sequence captured?
- Are timestamps accurate?
- Are justification links maintained?
```

---

## Educational Value Tests

**Test: Learning Through Doing**
```
Scenario: User new to projections

User: "Convert this file to web mapping format"
AI: "I'll reproject to EPSG:3857 (Web Mercator). This projection 
     is standard for web maps (Google Maps, Leaflet) because it 
     preserves angles and local shapes, though it distorts area 
     significantly at high latitudes."

Measure:
- Does AI explain *why* EPSG:3857?
- Is explanation contextual, not lecture?
- Can user learn projection concepts gradually?
```

**Test: Advisory Intervention**
```
Scenario: User makes suboptimal choice

User: "Reproject this global dataset to EPSG:3857 for area calculations"
AI: "I notice you want EPSG:3857 for area calculations. Web Mercator 
     significantly distorts area, especially near poles. For accurate 
     area calculations, an equal-area projection like Mollweide or 
     Albers would be better. Would you like me to suggest alternatives, 
     or proceed with Web Mercator as specified?"

Measure:
- Does AI detect concerning choices?
- Is intervention conversational, not blocking?
- Does user learn from the interaction?
```

---

## Performance Benchmarks

### Cache Hit Rate
```
Test workflow with 10 operations:
- 5 operations use EPSG:3857
- 3 operations use EPSG:32610
- 2 operations use EPSG:4326

Expected cache hit rate:
- First EPSG:3857: Miss (prompted)
- Next 4 EPSG:3857: Hit (4/4 = 100%)
- First EPSG:32610: Miss (prompted)
- Next 2 EPSG:32610: Hit (2/2 = 100%)
- Etc.

Target: >80% cache hit rate across workflow
```

### Operation Speed
```
Baseline measurements (approximate):
- vector_reproject: 1-5 seconds (depending on feature count)
- vector_convert: <1 second (format translation)
- vector_clip: 2-10 seconds (spatial operations)
- vector_buffer: 1-5 seconds (geometry generation)
- vector_simplify: 1-3 seconds (vertex reduction)

With reflection:
- First use: +10-30 seconds (LLM reasoning)
- Cache hit: +6ms (negligible)

Measure: Is cached performance acceptable?
```

---

## Failure Mode Tests

### Invalid CRS
```
User: "Reproject to EPSG:99999"

Expected:
- Clear error: "Invalid CRS specification"
- Suggestion: "Use standard formats like EPSG:3857, EPSG:4326"
- No crash, no silent failure
```

### Missing Source CRS
```
Input: Shapefile without .prj file

Expected:
- Error: "Source CRS not found and not provided"
- Instruction: "Please specify src_crs parameter"
- Example provided: src_crs="EPSG:4326"
```

### Unsupported Format
```
User: "Convert to .abc format"

Expected:
- Error: "Unsupported format: .abc"
- List supported: "Shapefile, GeoPackage, GeoJSON, KML, GML"
- Fallback to GeoPackage if extension unknown
```

---

## Success Criteria Summary

**Must Have:**
- [x] vector_reproject implemented and tested
- [ ] vector_convert implemented and tested
- [ ] Cross-domain reflection working (raster → vector cache hit)
- [ ] 3+ composition examples documented
- [ ] Cache hit rate >80% in multi-operation workflows

**Should Have:**
- [ ] vector_clip, vector_buffer, vector_simplify implemented
- [ ] Session tracking operational
- [ ] Natural workflow discovery demonstrated
- [ ] Educational value validated with user feedback

**Nice to Have:**
- [ ] Workflow guidance resources created
- [ ] Automatic pattern suggestions
- [ ] Performance optimizations
- [ ] Extended format support

---

## Testing Schedule

**Week 1:**
- [x] Implement vector_reproject
- [ ] Test cross-domain reflection (CRITICAL)
- [ ] Implement vector_convert
- [ ] Test basic format conversions

**Week 2:**
- [ ] Implement vector_clip, vector_buffer, vector_simplify
- [ ] Test composition scenarios
- [ ] Document success/failure patterns

**Week 3:**
- [ ] Session tracking implementation
- [ ] Performance benchmarking
- [ ] Educational value assessment

**Week 4:**
- [ ] Final integration testing
- [ ] Documentation updates
- [ ] Release preparation

---

## Notes

**Reflection Reuse Across Data Types:**
The key innovation in v1.1.0 is testing whether methodological reasoning transcends data formats. A CRS justified for raster analysis should apply equally to vector analysis. This requires:
- Consistent domain naming (`crs_datum`, not `raster_crs` or `vector_crs`)
- Identical cache key computation
- Same args_fn extraction
- Middleware domain-based, not tool-based

**Composition Discovery:**
We're testing whether models naturally chain operations or need explicit workflow prompts. This informs v2.x design:
- If models discover naturally → minimal scaffolding needed
- If models struggle → add workflow guidance resources
- Measure: success rate, user intervention needed, quality of results

**Educational Measurement:**
How do we know if the advisory pattern is working?
- User feedback: "I learned about projections today"
- Behavior change: Users make better choices over time
- Question patterns: Users ask "why" more often
- Confidence: Users explain their choices back to us

---

**Status:** Living document, updated as we test and learn
